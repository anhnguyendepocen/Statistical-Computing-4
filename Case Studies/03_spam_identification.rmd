---
title: ''
mainfont: Arial
fontsize: 12pt
documentclass: report
header-includes:
- \PassOptionsToPackage{table}{xcolor}
- \usepackage{caption}
- \usepackage{amssymb}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage[table]{xcolor}
- \usepackage{fancyhdr}
- \usepackage{boldline}
- \usepackage{tipa}
   \definecolor{headergrey}{HTML}{545454}
   \definecolor{msdblue}{HTML}{1C93D1}
   \pagestyle{fancy}
   \setlength\headheight{30pt}
   \rhead{\color{headergrey}\today}
   \fancyhead[L]{\color{headergrey}Moretz, Brandon}
   \fancyhead[C]{\Large\bfseries\color{headergrey}Spam Identification}
   \rfoot{\color{headergrey}Chapter 3}
   \lfoot{\color{headergrey}}
   \fancyfoot[C]{\rmfamily\color{headergrey}Case Studies In Data Science}
geometry: left = 1cm, right = 1cm, top = 2cm, bottom = 3cm
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
editor_options: 
  chunk_output_type: console
---


```{r knitr_setup, include = FALSE}

knitr::opts_chunk$set(
   echo = T, 
   eval = TRUE, 
   dev = 'png', 
   fig.width = 9, 
   fig.height = 4.5)

options(knitr.table.format = "latex")

```

```{r report_setup, message = FALSE, warning = FALSE, include = FALSE}

library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)
library(ggthemes, quietly = TRUE, warn.conflicts = FALSE)
library(scales, quietly = TRUE, warn.conflicts = FALSE)

library(knitr, quietly = TRUE, warn.conflicts = FALSE)
library(kableExtra, quietly = TRUE, warn.conflicts = FALSE)
library(pander, quietly = TRUE, warn.conflicts = FALSE)
library(formattable, quietly = TRUE, warn.conflicts = FALSE)

library(grid, quietly = TRUE, warn.conflicts = FALSE)
library(gridExtra, quietly = TRUE, warn.conflicts = FALSE)
library(extrafont, quietly = TRUE, warn.conflicts = FALSE)
library(tinytex, quietly = TRUE, warn.conflicts = FALSE)

library(here, quietly = TRUE, warn.conflicts = FALSE)

library(codetools, quietly = TRUE, warn.conflicts = FALSE)
library(lattice, quietly = TRUE, warn.conflicts = FALSE)
library(fields, quietly = TRUE, warn.conflicts = FALSE)
library(RColorBrewer, quietly = TRUE, warn.conflicts = FALSE)
library(tm, quietly = TRUE, warn.conflicts = FALSE)

library(rbenchmark, quietly = TRUE, warn.conflicts = FALSE)

options(tinytex.verbose = TRUE)
suppressMessages(library("tidyverse"))

pretty_kable <- function(data, title, dig = 2) {
  kable(data, caption = title, digits = dig) %>%
    kable_styling(bootstrap_options = c("striped", "hover")) %>%
      kableExtra::kable_styling(latex_options = "hold_position")
}

theme_set(theme_light())

# Theme Overrides
theme_update(axis.text.x = element_text(size = 10),
             axis.text.y = element_text(size = 10),
             plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "darkgreen"),
             axis.title = element_text(face = "bold", size = 12, colour = "steelblue4"),
             plot.subtitle = element_text(face = "bold", size = 8, colour = "darkred"),
             legend.title = element_text(size = 12, color = "darkred", face = "bold"),
             legend.position = "right", legend.title.align=0.5,
             panel.border = element_rect(linetype = "solid", 
                                         colour = "lightgray"), 
             plot.margin = unit(c( 0.1, 0.1, 0.1, 0.1), "inches"))

data.dir <- file.path(here::here(), "Case Studies", "datasets", "spam")

```

```{r pander_setup, include = FALSE}

knitr::opts_chunk$set(comment = NA)

panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)

```

# Using Statistics to Identify Spam

## Anatomy of an email Message

### Spam Data

```{r}

head(list.files(path = file.path(data.dir, "easy_ham")))
head(list.files(path = file.path(data.dir, "spam_2")))

directories <- paste(data.dir, list.files(data.dir), sep = .Platform$file.sep)

file_counts <- sapply(directories, function(dir) length(list.files(dir)))

total_files <- sum(file_counts)
total_files
```

```{r}
file_counts

idx <- c(1:5, 15, 27, 68, 69, 329, 404, 427, 516, 852, 971)

fn <- list.files(directories[1], full.names = T)[idx]

sampleEmail <- sapply(fn, readLines)
```

### Text Mining and Naive Bayes Classification

```{r}
msg <- sampleEmail[[1]]
which(msg == "")[1]

match("", msg)

splitPoint <- match("", msg)

msg[ (splitPoint - 2):(splitPoint + 6)]

header <- msg[1:(splitPoint - 1)]
body <- msg[ -(1:splitPoint) ]

```


```{r}

splitMessage <- function(msg) {
   splitPoint <- match("", msg)
   
   header <- msg[ 1:(splitPoint - 1)]
   body <- msg[ -(1:splitPoint)]
   
   return(list(header = header, body = body))
}

sampleSplit <- lapply(sampleEmail, splitMessage)

header <- sampleSplit[[1]]$header
grep("Content-Type", header)
grep("multi", tolower(header))

header[46]

headerList <- lapply(sampleSplit, function(msg) msg$header)

CTloc <- sapply(headerList, grep, pattern = "Content-Type")
CTloc

sapply(headerList, function(header) {
   CTloc <- grep("Content-Type", header)
   if( length(CTloc) == 0) return(NA)
   CTloc
})

hasAttach <- sapply(headerList, function(header) {
   CTloc <- grep("Content-Type", header)
   
   if(length(CTloc) == 0) return(F)
   grepl("multi", tolower(header[CTloc]))
})

hasAttach

header <- sampleSplit[[6]]$header
boundaryIdx <- grep("boundary=", header)
header[boundaryIdx]

sub(".*boundary=\"(.*)\";.*", "\\1", header[boundaryIdx])

header2 <- headerList[[9]]
boundaryIdx2 <- grep("boundary=", header2)
header2[boundaryIdx2]

sub('.*boundary="(.*)";.*', "\\1", header2[boundaryIdx2])

boundary2 <- gsub('"', "", header2[boundaryIdx2])

sub(".*boundary= *(.*);?.*", "\\1", boundary2)

boundary <- gsub('"', "", header[boundaryIdx])
sub(".*boundary= *(.*);?.*", "\\1", boundary)

```

```{r}

getBoundary <- function(header) {
   boundaryIdx <- grep("boundary=", header)
   boundary = gsub('"', "", header[boundaryIdx])
   gsub(".*boundary= *([^;]*);?.*", "\\1", boundary)
}

```

```{r}

boundary <- getBoundary(headerList[[15]])
body <- sampleSplit[[15]]$body

bString <- paste("--", boundary, sep = "")
bStringLocs <- which(bString == body)
bStringLocs

eString <- paste("--", boundary, "--", sep = "")
eStringLoc <- which(eString == body)
eStringLoc

msg <- body[ (bStringLocs[1] + 1) : (bStringLocs[2] - 1)]
tail(msg)

msg <- c(msg, body[ (eStringLoc + 1) : length(body) ])
tail(msg)

```

### Handle Attachments

```{r}


```

### Extracting Words from the Message Body

```{r}
head(sampleSplit[[1]]$body)

msg <- sampleSplit[[3]]$body
head(msg)

```

### Stemming

```{r}
exclude_word_list <- stopwords(kind = "en")
```

### Convert To Wordlist

```{r}
tolower(gsub("[[:punct:]0-9[:blank:]]+", " ", msg))

msg[ c(1, 3, 26, 27) ]

cleanMsg <- tolower(gsub("[[:punct:]0-9[:blank:]]+", " ", msg))
cleanMsg[ c(1, 3, 26, 27) ]

words <- unlist(strsplit(cleanMsg, "[[:blank:]]+"))

words <- words[ nchar(words) > 1 ]

words <- words[ ! (words %in% exclude_word_list) ]

head(words)

```

```{r}

findMsgWords <- function(msg, exclude) {
   
   cleanMsg <- tolower(gsub("[[:punct:]0-9[:blank:]]+", " ", msg))

   words <- unlist(strsplit(cleanMsg, "[[:blank:]]+"))
   
   keep <- sapply(words, function(word) return(!(word %in% exclude)))
   
   
   return(words[ keep ])   
}

```

### Prep Wrap-Up

```{r}

dropAttach <- function(body, boundary) {
   
   if(is.null(body)) {
      return("")
   }
   
   bString <- paste("--", boundary, sep = "")
   bStringLocs <- which(bString == body)
   
   eString <- paste("--", boundary, "--", sep = "")
   eStringLoc <- which(eString == body)
   
   if(length(bStringLocs) == 2) {
      msg <- body[ (bStringLocs[1] + 1) : (bStringLocs[2] - 1)]
   }
   
   if(length(eStringLoc) > 0) {
      msg <- c(msg, body[ (eStringLoc + 1) : length(body) ])
   }
   
   return(msg)
}

processAllWords <- function(dirName, stopWords) {
   # read all files in the directory
   fileNames <- list.files(dirName, full.names = T)
   
   # drop files that are not email, i.e., cmds
   notEmail <- grep("cmds$", fileNames)
   
   if( length(notEmail) > 0) fileNames <- fileNames[ -notEmail ]
   
   messages <- lapply(fileNames, readLines, encoding = "latin1")
   
   # split header and body
   emailSplit <- lapply(messages, splitMessage)
   
   # put body and header in own lists
   bodyList <- lapply(emailSplit, function(msg) msg$body)
   headerList <- lapply(emailSplit, function(msg) msg$header)
   rm(emailSplit)
   
   # determine which messages have attachments
   hasAttach <- sapply(headerList, function(header) {
      
      CTloc <- grep("Content-Type", header)
      
      if( length(CTloc) == 0) return(0)
      
      multi <- grep("multi", tolower(header[CTloc]))
      
      if( length(multi) == 0 ) return(0)
      
      multi
   })
   
   hasAttach <- which(hasAttach > 0)
   
   # find boundary string for messages with attachments
   boundaries <- sapply(headerList[hasAttach], getBoundary)
   
   # drop attachments from message body
   bodyList[hasAttach] <- mapply(dropAttach, bodyList[hasAttach],
                                 boundaries, SIMPLIFY = F)
   
   # extract words from body
   msgWordsList <- lapply(bodyList, findMsgWords, stopWords)
   
   invisible(msgWordsList)
}
```

### Build Email Database

```{r}

msgWordList <- lapply(directories, processAllWords, stopWords = exclude_word_list)

numMsgs <- sapply(msgWordList, length)
numMsgs

isSpam <- rep(c(FALSE, FALSE, FALSE, TRUE, TRUE), numMsgs)

msgWordsList <- unlist(msgWordList, recursive = F)

```

## Naive Bayes Classifier Implementation

### Train / Test Split

```{r}
numEmail <- length(isSpam)

numSpam <- sum(isSpam)
numHam <- numEmail - numSpam

set.seed(418910)

testSpamIdx <- sample(numSpam, size = floor(numSpam/3))
testHamIdx <- sample(numHam, size = floor(numHam/3))

testMsgWords <- c((msgWordsList[isSpam])[testSpamIdx],
                  (msgWordsList[!isSpam])[testHamIdx])

trainMsgWords <- c((msgWordsList[isSpam])[ - testSpamIdx ],
                   (msgWordsList[!isSpam])[ - testHamIdx])

testIsSpam <- rep(c(T, F), 
                  c(length(testSpamIdx), length(testHamIdx)))

trainIsSpam <- rep(c(T, F),
                   c(numSpam - length(testSpamIdx),
                     numHam - length(testHamIdx)))

```

### Probability Estimates from Training Sample

```{r}
bow <- unique(unlist(trainMsgWords))

length(bow)
```

```{r}
spamWordCounts <- rep(0, length(bow))

names(spamWordCounts) = bow

tmp <- lapply(trainMsgWords[trainIsSpam], unique)
tt <- table( unlist(tmp) )
spamWordCounts[ names(tt) ] = tt

spamWordsProbs <- (spamWordCounts + 0.5) / (sum(trainIsSpam) + 0.5)

spamWordsProbs[1:20]

hamWordCounts <- rep(0, length(bow))

names(hamWordCounts) = bow

tmp <- lapply(trainMsgWords[ - trainIsSpam], unique)
tt <- table( unlist(tmp) )
hamWordCounts[ names(tt) ] = tt

hamWordsProbs <- (hamWordCounts + 0.5) / (sum(!trainIsSpam) + 0.5)

probs <- log(spamWordsProbs) - log(hamWordsProbs)

head(probs)
```

```{r}
wordsList <- trainMsgWords
spam <- trainIsSpam

make_words_valid_columns <- function( words, all_words ) {
   
   word_counts <- rep(0, length(all_words))
   names(word_counts) <- all_words
   
   tmp <- lapply(words, unique)
   tt <- table( unlist(tmp) )
   word_counts[ names(tt) ] = tt

   return(word_counts)
}

computeFreqs <- function(wordsList, spam, bow = unique(unlist(wordsList))) {
   
   all_words <- unique(bow)
   
   # create a matrix for spam, ham, and log odds
   wordTable <- matrix(0.5, nrow = 2, ncol = length(bow))
   colnames(wordTable) <- all_words
   rownames(wordTable) <- c( "presentLogOdds",
                          "absentLogOdds")
   
   # for each spam message, add 1 to the counts for words in messsage
   
   spam_all <- wordsList[spam]
   spam_words <- make_words_valid_columns( spam_all, all_words )

   wordTable <- rbind(wordTable, spam_words + 0.5)
   rownames(wordTable)[3] <- "spam"
   
   # Similarly for ham messages
   
   ham_all <- wordsList[ !spam ]
   
   ham_words <- make_words_valid_columns( ham_all, all_words )
   
   wordTable <- rbind(wordTable, ham_words + 0.5)
   rownames(wordTable)[4] <- "ham"
   
   head(wordTable[, 1:20])
   
   # find the total number of spam and ham
   numSpam <- sum(spam)
   numHam <- length(spam) - numSpam
   
   # prob (word|spam) and prob(words|ham)
   wordTable["spam", ] <- wordTable["spam", ] / (numSpam + 0.5)
   wordTable["ham", ] <- wordTable["ham", ] / (numHam + 0.5)
   
   head(wordTable[, 1:20])
   
   # log odds
   wordTable["presentLogOdds", ] = 
      log(wordTable["spam", ]) - log(wordTable["ham", ])
   
   wordTable["absentLogOdds", ] =
      log((1 - wordTable["spam", ])) - log((1 - wordTable["ham", ]))
   
   invisible(wordTable)
}

```

```{r}
trainTable <- computeFreqs(trainMsgWords, trainIsSpam)

# peek the prob table
head(trainTable[, 1:10])
```

### Classifying New Messages

```{r}
newMsg <- testMsgWords[[1]]

# only look at words we have classified
newMsg <- newMsg[ !is.na(match(newMsg, colnames(trainTable)))]

present <- colnames(trainTable) %in% newMsg

sum( trainTable["presentLogOdds", present]) +
   sum( trainTable["absentLogOdds", !present])

newMsg <- testMsgWords[[ which(!testIsSpam)[ 1 ] ]]
newMsg <- newMsg[ !is.na(match(newMsg, colnames(trainTable)))]
present <- (colnames(trainTable) %in% newMsg)

sum(trainTable["presentLogOdds", present]) +
   sum(trainTable["absentLogOdds", !present])

```

```{r}

computeMsgLLR <- function(words, freqTable) {
   
   # discard words not in training data
   words <- words[!is.na(match(words, colnames(freqTable)))]
   
   # Find which words are present
   present <- colnames(freqTable) %in% words
   
   sum(freqTable["presentLogOdds", present]) +
      sum(freqTable["absentLogOdds", !present])
}

```

```{r}
testLLR <- sapply(testMsgWords, computeMsgLLR, trainTable)
```

```{r}
tapply(testLLR, testIsSpam, summary)
```

```{r}
results_df <- data.table( score = testLLR, class = testIsSpam )

ggplot(results_df, aes(score, class, fill = class)) +
   geom_boxplot() +
   coord_flip()   
```

```{r}
typeIErrorRate <- function(tau, llrVals, spam) {
   classify <- llrVals > tau
   sum(classify & !spam) / sum(!spam)
}

typeIErrorRate(0, testLLR, testIsSpam)
typeIErrorRate(-20, testLLR, testIsSpam)

error_rates <- sapply(seq(-30, 30, 1), function(cutoff) c(cutoff = cutoff, rate = typeIErrorRate(cutoff, testLLR, testIsSpam)))

er_df <- data.table(t(error_rates))

ggplot(er_df, aes(cutoff, rate)) +
   geom_line(col = "darkblue") +
   labs(title = "False Positive Error Rates")
```

```{r}
typeIErrorRates <- function(llrVals, isSpam) {
   o <- order(llrVals)
   llrVals <- llrVals[o]
   isSpam <- isSpam[o]
   
   idx <- which(!isSpam)
   N <- length(idx)
   list(error = (N:1)/N, values = llrVals[idx])
}


```

### Computational Considerations

```{r}
smallNums <- rep((1/2)^40, 2000000)
largeNum <- 10000

print(sum(smallNums), digits = 20)

print(largeNum + sum(smallNums), digits = 20)

for(i in 1:length(smallNums)) {
   largeNum <- largeNum + smallNums[i]
}

print(largeNum, digits = 20)
```

## Recursive Partitioning and Classification Trees

### Revised E-mail Data Structure

```{r}
header <- sampleSplit[[1]]$header

header[1:12]

header[1] = sub("^From", "Top-From:", header[1])

headerPieces <- read.dcf(textConnection(header), all = T)

headerPieces[, "Delivered-To"]

headerVec <- unlist(headerPieces)
dupKeys <- sapply(headerPieces, function(x) length(unlist(x)))
names(headerVec) <- rep(colnames(headerPieces), dupKeys)

headerVec[ which(names(headerVec) == "Delivered-To") ]

length(headerVec)

length(unique(names(headerVec)))
```

```{r}
processHeader <- function(header) {
   # modify the first line to create a key:value pair
   header[1] <- sub("^From", "Top-From:", header[1])
   
   headerMat <- read.dcf(textConnection(header), all = T)
   headerVec <- unlist(headerMat)
   
   dupKeys <- sapply(headerMat, function(x) length(unlist(x)))
   names(headerVec) <- rep(colnames(headerMat), dupKeys)
   
   return(headerVec)
}

headerList <- lapply(sampleSplit,
                     function(msg) {
                        processHeader(msg$header)
                     })

contentTypes <- sapply(headerList, function(header)
   header["Content-Type"])

names(contentTypes) <- NULL

contentTypes
```

#### Attachments Revisited

```{r}
hasAttach <- grep("^ *multi", tolower(contentTypes))
hasAttach

boundaries <- getBoundary(contentTypes[ hasAttach ])
boundaries

boundary <- boundaries[9]
body <- sampleSplit[[15]]$body

bString <- paste("--", boundary, sep = "")
bStringLocs <- which(bString == body)
bStringLocs

eString <- paste("--", boundary, "--", sep = "")
eStringLoc <- which(eString == body)
eStringLoc

range <- diff(c(bStringLocs[-1], eStringLoc))

body[1:range]

```

```{r}

processAttach <- function(body, contentType ) {

   boundary <- getBoundary(contentType)

   bString <- paste("--", boundary, sep = "")
   bStringLocs <- which(bString == body)

   eString <- paste("--", boundary, "--", sep = "")
   eStringLoc <- which(eString == body)
   
   n <- length(body)
   
   if(length(bStringLocs) == 2) {
      
      bodyContent <- body[(bStringLocs[1] + 2):(bStringLocs[2] - 1)]

      emptyLines <- which(bodyContent == "")
      bodyContent <- bodyContent[ - emptyLines]
    
      attachContent <- body[(bStringLocs[2] + 1):n]
      
      aLen <- diff(c(bStringLocs[-1], eStringLoc))
      aType <- body[bStringLocs[-1] + 1]
      
      if(length(aLen) == length(aType)) {      
         attachments <- data.frame(aLen = aLen, aType = aType)
      } else {
         attachments <- data.frame(aLen = c(), aType = c())
      }
      
   } else {
      if( length(bStringLocs) == 0 ) {
         bodyContent <- body
      } else {
         bodyContent = body
      }
      attachments <- data.frame(aLen = c(), aType = c())
   }
   
   return(list(body = bodyContent, attachDF = attachments ))
}

```

#### More E-Mails

```{r}

bodyList <- lapply(sampleSplit, function(msg) msg$body)
attList <- mapply(processAttach, bodyList[hasAttach],
                  contentTypes[hasAttach], SIMPLIFY = F)

lens <- sapply(attList, function(processedA)
                           processedA$attachDF$aLen)
```

```{r}
readEmail <- function(dirName) {
   # retrieve the names of files in the directory
   fileNames <- list.files(dirName, full.names = T)
   
   # drop files that are not email
   notEmail <- grep("cmds$", fileNames)
   
   if( length(notEmail) > 0 ) fileNames = fileNames[ - notEmail ]
   
   # read all files in the directory
   lapply(fileNames, readLines, encoding = "latin1")
}

processAllEmail <- function(dirName, isSpam = F) {
   
   # read all files in the directory
   messages <- readEmail(dirName)
   
   fileNames <- names(messages)
   n <- length(messages)
   
   # split header from body
   eSplit <- lapply(messages, splitMessage)
   rm(messages)
   
   # process header as named character vector
   headerList <- lapply(eSplit, function(msg)
                           processHeader(msg$header))
                        
   # extractd content-type key                        
   contentTypes <- sapply(headerList, function(header)
                                       header["Content-Type"])
   
   # extract the body
   bodyList <- lapply(eSplit, function(msg) msg$body)
   rm(eSplit)
   
   # which email have attachements
   hasAttach <- grep("^ *multi", tolower(contentTypes))
   
   # get summary stats for attachments and the shorter body
   attList <- mapply(processAttach, bodyList[hasAttach],
                     contentTypes[hasAttach], SIMPLIFY = F)
   
   bodyList[hasAttach] <- lapply(attList, function(attEl)
                                             attEl$body)
   
   attachInfo <- vector("list", length = n)
   attachInfo[ hasAttach ] <- lapply(attList,
                                     function(attEl) attEl$attachDf)
   
   # prepare return structure
   emailList <- mapply(function(header, body, attach, isSpam) {
      list(isSpam = isSpam, header = header,
           body = body, attach = attach)
   },
   headerList, bodyList, attachInfo,
   rep(isSpam, n), SIMPLIFY = F)

   names(emailList) <- fileNames
   
   invisible(emailList)
}

```

```{r}
emailStruct <- mapply(processAllEmail, directories,
                      isSpam = rep( c(F, T), 3:2))
emailStruct <- unlist(emailStruct, recursive = F)
```

```{r}
sampleStruct <- emailStruct[ 1 ]
```

### Deriving Variables from the email Messages

```{r}

```

