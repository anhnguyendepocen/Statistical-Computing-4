---
title: ''
mainfont: Arial
fontsize: 12pt
documentclass: report
header-includes:
- \PassOptionsToPackage{table}{xcolor}
- \usepackage{caption}
- \usepackage{amssymb}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage[table]{xcolor}
- \usepackage{fancyhdr}
- \usepackage{boldline}
- \usepackage{tipa}
   \definecolor{headergrey}{HTML}{545454}
   \definecolor{msdblue}{HTML}{1C93D1}
   \pagestyle{fancy}
   \setlength\headheight{30pt}
   \rhead{\color{headergrey}\today}
   \fancyhead[L]{\color{headergrey}Moretz, Brandon}
   \fancyhead[C]{\Large\bfseries\color{headergrey}Introduction to Hypothesis - Testing Permutation Tests}
   \rfoot{\color{headergrey}Chapter 3}
   \lfoot{\color{headergrey}}
   \fancyfoot[C]{\rmfamily\color{headergrey}Mathematical Statistics}
geometry: left = 1cm, right = 1cm, top = 2cm, bottom = 3cm
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
editor_options: 
  chunk_output_type: console
---


```{r knitr_setup, include = FALSE}

# DO NOT ADD OR REVISE CODE HERE
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, dev = 'png')
options(knitr.table.format = "latex")

```

```{r report_setup, message = FALSE, warning = FALSE, include = FALSE}

library(data.table, quietly = TRUE, warn.conflicts = FALSE)

assignInNamespace("cedta.pkgEvalsUserCode", c(data.table:::cedta.pkgEvalsUserCode, "rtvs"), "data.table")

library(ggplot2, quietly = TRUE, warn.conflicts = FALSE)
library(ggrepel, quietly = TRUE, warn.conflicts = FALSE)
library(ggthemes, quietly = TRUE, warn.conflicts = FALSE)
library(knitr, quietly = TRUE, warn.conflicts = FALSE)
library(kableExtra, quietly = TRUE, warn.conflicts = FALSE)
library(scales, quietly = TRUE, warn.conflicts = FALSE)
library(pander, quietly = TRUE, warn.conflicts = FALSE)
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)
library(formattable, quietly = TRUE, warn.conflicts = FALSE)
library(grid, quietly = TRUE, warn.conflicts = FALSE)
library(gridExtra, quietly = TRUE, warn.conflicts = FALSE)
library(png, quietly = TRUE, warn.conflicts = FALSE)
library(extrafont, quietly = TRUE, warn.conflicts = FALSE)
library(tinytex, quietly = TRUE, warn.conflicts = FALSE)
library(stringr, quietly = TRUE, warn.conflicts = FALSE)
library(lubridate, quietly = TRUE, warn.conflicts = FALSE)
library(reshape2, quietly = TRUE, warn.conflicts = FALSE)
library(ggrepel, quietly = TRUE, warn.conflicts = FALSE)
library(mnormt, quietly = TRUE, warn.conflicts = FALSE)
library(Ecdat, quietly = TRUE, warn.conflicts = FALSE)
library(MASS, quietly = TRUE, warn.conflicts = FALSE)
library(copula, quietly = TRUE, warn.conflicts = FALSE)
library(fGarch, quietly = TRUE, warn.conflicts = FALSE)
library(forecast, quietly = TRUE, warn.conflicts = FALSE)
library(tseries, quietly = TRUE, warn.conflicts = FALSE)
library(gmodels, quietly = TRUE, warn.conflicts = FALSE)
library(rugarch, quietly = TRUE, warn.conflicts = FALSE)
library(quantmod, quietly = TRUE, warn.conflicts = FALSE)
library(gtools, quietly = TRUE, warn.conflicts = FALSE)

options(tinytex.verbose = TRUE)
suppressMessages(library("tidyverse"))

pretty_kable <- function(data, title, dig = 2) {
  kable(data, caption = title, digits = dig) %>%
    kable_styling(bootstrap_options = c("striped", "hover")) %>%
      kableExtra::kable_styling(latex_options = "hold_position")
}

theme_set(theme_light())

# Theme Overrides
theme_update(axis.text.x = element_text(size = 10),
             axis.text.y = element_text(size = 10),
             plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "darkgreen"),
             axis.title = element_text(face = "bold", size = 12, colour = "steelblue4"),
             plot.subtitle = element_text(face = "bold", size = 8, colour = "darkred"),
             legend.title = element_text(size = 12, color = "darkred", face = "bold"),
             legend.position = "right", legend.title.align=0.5,
             panel.border = element_rect(linetype = "solid", 
                                         colour = "lightgray"), 
             plot.margin = unit(c( 0.1, 0.1, 0.1, 0.1), "inches"))

data.dir <- "D:/Projects/Statistical-Computing/datasets/"

setwd("D:/Projects/Statistical-Computing/RDS")

```

```{r pander_setup, include = FALSE}

knitr::opts_chunk$set(comment = NA)

panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)

```

#### Chapter 3 Exercises

### 3.1

Suppose you conduct an experiment and inject a drug into three mice.

Their times for running a maze are 8, 10, 15 s; the times for two control mice are 5 and 9 s.

a.) Compute the difference in mean times between the treatment group and the control group.

```{r, echo = T}

mice.t <- c(8, 10, 15)
mice.c <- c(5, 9)

observed <- mean(mice.t) - mean(mice.c)

observed
```

b.) Write out all the possible permutations of these times to the two groups and calculate the diffence in means.

```{r, echo = T}

mice <- c(mice.t, mice.c)

# 5 choose 3 for treatment

treatment <- combinations(n = 5, r = 3, mice, repeats.allowed = F)

control <- matrix(nrow = 10, ncol = 2)
for( i in 1:nrow(control))
{
  control[i,] <- mice[!mice %in% treatment[i,]]
}

perms <- data.table(cbind(treatment, control))

stopifnot(nrow(perms) == choose(5, 3))

colnames(perms) <- c("D1", "D2", "D3", "C1", "C2")

perms$Xd <- (perms$D1 + perms$D2 + perms$D3) / 3
perms$Xc <- (perms$C1 + perms$C2) / 2
perms$Diff <- round(perms$Xd - perms$Xc, 2)

```

\newpage

```{r, echo = F}
pretty_kable(perms, "Mice Permutations")
```

c.) What proportion of the differences are as large or larger than the observed differences in mean times?

```{r, echo = T}

gte.observed <- perms[Diff >= observed]

pretty_kable(gte.observed, "Greater than or Equal to Observed")

p1c <- nrow(gte.observed) / nrow(perms)

```

__Proportion of differences greater than or equal to observed: `r p1c*100`%__

d.) For each permutation, calculate the mean of the treatment group only.

What proportion of these means are as large or larger than the observed mean of the treatment group?

```{r, echo = T}

gte.t <- perms[ Xd >= mean(mice.t),]
pretty_kable(gte.t, "Mean Treatment Greater than or Equal to Observed")

p1d <- nrow(gte.t) / nrow(perms)

```

__Proportion of treatment groups greater than observed: `r p1d*100`%__

### 3.2

Your statistics professor comes to class with a big urn that she claims contains 9,999 blue marbels and 1 red marble.

You draw our one marble at random and finds that it is red.

Would you be willing to tell your professor that you think she is wrong about the distribution of colors?

Why or why not?

+ Yes, a 1/10,000 chance is pretty rare.

What are you assuming in making your decision?

What if instead, she claims there are nine blue marbles and 1 red one (and you draw out a red marble)?

+ A 1/10 chance is fairly common.

### 3.3

In a hypothesis test comparing two populations means, $H_0 : \mu_1 = \mu_2\ versus \ H_A : \mu_1 > \mu_2$

__a.)__ Which P-value, _0.03_ or _0.006_, provides stronger evidence for the alternative hypothesis?

_0.03_ provides stronger evidence for the alternative hypothesis.

__b.)__ Which P-value, 0.095 or 0.04, provides stronger evidence that chance alone might account for the observed result?

_0.095_ provides stronger evidence that chance alone is responsible for the observed result.

### 3.4

In the algorithms for conducting a permutation test, why do we add 1 to the number of replications N when calculating the P-Value?

__Answer__: We need to account for the original observed result.

### 3.5

In the flight delays case study in Section 1.1, the data contain flight delays for two airlines, American Airlines and United Airlines.

```{r, echo = T}

Flights <- data.table(read.csv(paste0(data.dir, "FlightDelays.csv"),
                               header = T))

```

a.) Conduct a two-sided permutation test to see if the difference in mean delay times between the two carriers are statistically significant.

```{r, echo = T, fig.height=3.5, fig.width=8}

Flights[, .(Delay = mean(Delay)), by = Carrier]

observed <- mean(Flights[Carrier == "UA"]$Delay) - mean(Flights[Carrier == "AA"]$Delay)

N <- 10e2 - 1
results <- numeric(N)

for(i in 1:N)
{
   index <- sample(nrow(Flights), nrow(Flights[Carrier == "UA"]), replace = F)
   results[i] <- mean(Flights[index]$Delay) - mean(Flights[-index]$Delay)
}

# two-sided test
p <- 2 * (sum(results[results >= observed]) + 1) / ( N + 1)
v <- p*(1 - p) / ( N + 1 )

ggplot(data.table(results)) +
   geom_histogram(aes(results, fill = ..count..), bins = 30) +
   geom_vline(xintercept = observed, col = "darkorange", linetype = 3, lwd = 1.2) +
   scale_y_continuous(labels = comma) +
   labs(title = paste0("Flight Delay Times, UA/AA vs Observed, p=", round(p, 5)),
        subtitle = paste0("Observed Value: ", round(observed, 4)))

```

b.) The flights took place in May and June of 2009. Conduct a two-sided permutation test to see if the differences in mean delay times between two months is statistically significant.

```{r, echo = T, fig.height=3.5, fig.width=8}

Flights[, .(Delay = mean(Delay)), by = Month]

observed <- mean(Flights[Month == "May"]$Delay) - mean(Flights[Month == "June"]$Delay)

N <- 10e2 - 1
results <- numeric(N)

for(i in 1:N)
{
   index <- sample(nrow(Flights), nrow(Flights[Month == "May"]), replace = F)
   results[i] = mean(Flights[index]$Delay) - mean(Flights[-index]$Delay)
}

# two-sided test

p <- 2 * (sum(results[results <= observed]) + 1) / ( N + 1)
v <- p*(1 - p) / ( N + 1 )

ggplot(data.table(results)) +
   geom_histogram(aes(results, fill = ..count..), bins = 30) +
   geom_vline(xintercept = observed, col = "darkorange", linetype = 3, lwd = 1.2) +
   scale_y_continuous(labels = comma) +
   labs(title = paste0("Flight Delay Times, May/June, vs Observed, p=", round(p, 5)),
        subtitle = paste0("Observed Value: ", round(observed, 4)))

```

### 3.6

In the flight delays case study in Section 1.1, the data contains flight delays for two airlines, American and United.

a.) Compute the proportion of times that each carrier's flight was delays more than 20 min.

```{r, echo = T, fig.height=3.5, fig.width=8}

Flights[, .(Delay20 = sum(Delay > 20) / .N), by = Carrier]

observed <- as.numeric(Flights[Carrier == "UA", .(Delay = sum(Delay > 20)/.N)] - Flights[Carrier == "AA", .(Delay = sum(Delay > 20)/.N)])

N <- 10e2 - 1
results <- numeric(N)

for(i in 1:N)
{
   index <- sample(nrow(Flights), nrow(Flights[Carrier == "UA"]), replace = F)
   results[i] <- as.numeric(Flights[index, .(Delay = sum(Delay > 20)/.N)] - Flights[-index, .(Delay = sum(Delay > 20)/.N)])
}

p <- 2 * (sum(results[results >= observed]) + 1) / ( N + 1)
v <- p*(1 - p) / ( N + 1 )

ggplot(data.table(results)) +
   geom_histogram(aes(results, fill = ..count..), bins = 30) +
   geom_vline(xintercept = observed, col = "darkorange", linetype = 3, lwd = 1.2) +
   scale_y_continuous(labels = comma) +
   labs(title = paste0("Flight Delay Times, Over 20 Minutes, vs Observed, p=", round(p, 5)), 
        subtitle = paste0("Observed Value: ", round(observed, 4)))

```

+ Conduct a two-sided test to see if the difference in these proportions is statistically significant.

__Answer__: There is statistical significance with a P-value < 0.0001.

b.) Compute the variance in the flight delay lengths for each carrier.

```{r, echo = T, fig.height=3.5, fig.width=8}

Flights[, .(Variance = var(Delay)), by = Carrier]

observed <- var(Flights[Carrier == "UA"]$Delay) - var(Flights[Carrier == "AA"]$Delay)

N <- 10e2 - 1
results <- numeric(N)

for(i in 1:N)
{
   index <- sample(nrow(Flights), nrow(Flights[Carrier == "UA"]), replace = F)
   results[i] <- var(Flights[index]$Delay) - var(Flights[-index]$Delay)
}

p <- min(1, 2 * (sum(results[results >= observed]) + 1) / ( N + 1))
v <- p*(1 - p) / ( N + 1 )

ggplot(data.table(results)) +
   geom_histogram(aes(results, fill = ..count..), bins = 30) +
   geom_vline(xintercept = observed, col = "darkorange", linetype = 3, lwd = 1.2) +
   scale_y_continuous(labels = comma) +
   labs(title = paste0("Flight Delay Time Variance, vs Observed, p=", round(p, 5)), 
        subtitle = paste0("Observed Value: ", round(observed, 4)))

```

+ Conduct a test to see if the variance for United Airlines differes from that of American Airlines.

__Answer__: There does not appear to be a statistically significant difference in the variance in delay times between airlines.

\newpage

### 3.7

In the flight delays case study in Section 1.1, repeat Excercise 3.5 part __(a)__ using three test statistics, 

+ i.) The mean of the United Airline delay times
+ ii.) The sum of the United Airline delay times
+ iii.) The difference in the means

Compare the P-values.

Make sure all three test statistics are computed within the same __for__ loop.

What do you observe?

```{r, echo = T, fig.height=7.5, fig.width=8}

UA.Delay <- Flights[Carrier == "UA"]$Delay
AA.Delay <- Flights[Carrier == "AA"]$Delay

observed.mean <- mean(UA.Delay)
observed.sum <- sum(UA.Delay)
observed.diff <- mean(UA.Delay) - mean(AA.Delay)

N <- 10e2 - 1
results <- matrix(nrow = N, ncol = 3)

for(i in 1:N)
{
   index <- sample(nrow(Flights), length(UA.Delay), replace = F)

   results[i, 1] <- mean(Flights[index]$Delay)
   results[i, 2] <- sum(Flights[index]$Delay)
   results[i, 3] <- mean(Flights[index]$Delay) - mean(Flights[-index]$Delay)
}

dt.results <- data.table(results)
colnames(dt.results) <- c("Mean", "Sum", "MeanDiff")

p.mean <- ( sum( dt.results$Mean >= observed.mean ) + 1 ) / ( N + 1)
p.sum <- ( sum(dt.results$Sum >= observed.sum) + 1) / ( N + 1 )
p.diff <- ( sum(dt.results$MeanDiff >= observed.diff) + 1) / ( N + 1)

p1 <- ggplot(dt.results) +
   geom_histogram(aes(Mean, fill = ..count..), bins = 30) +
   geom_vline(xintercept = observed.mean, col = "darkorange", lwd = 1.2, linetype = 3) +
   scale_y_continuous(labels = comma) +
   labs(title = paste0("United Airlines - Mean Delay Time vs Observed, p=", round(p.mean, 5)), 
        subtitle = paste0("Observed Value: ", round(observed.mean, 4)))

p2 <- ggplot(dt.results) +
   geom_histogram(aes(Sum, fill = ..count..), bins = 30) +
   geom_vline(xintercept = observed.sum, col = "darkorange", lwd = 1.2, linetype = 3) +
   scale_y_continuous(labels = comma) +
   labs(title = paste0("United Airlines - Sum Delay Time vs Observed, p=", round(p.sum, 5)), 
        subtitle = paste0("Observed Value: ", round(observed.sum, 4)))

p3 <- ggplot(dt.results) +
   geom_histogram(aes(MeanDiff, fill = ..count..), bins = 30) +
   geom_vline(xintercept = observed.diff, col = "darkorange", lwd = 1.2, linetype = 3) +
   scale_y_continuous(labels = comma) +
   labs(title = paste0("Mean Delay Time Difference vs Observed, p=", round(p.diff, 5)), 
        subtitle = paste0("Observed Value: ", round(observed.diff, 4)))

grid.arrange(p1, p2, p3, nrow = 3)

```

\newpage

### 3.8

In the flight delays case study in Section 1.1,

a.) Find the trimmed mean of the delay times for United Airlines and American Airlines.

```{r, echo = T}

trim.amount <- .25
UA.trimmed <- mean(UA.Delay, trim = trim.amount)
AA.trimmed <- mean(AA.Delay, trim = trim.amount)

observed <- UA.trimmed - AA.trimmed

pretty_kable(data.table( UA = UA.trimmed, AA = AA.trimmed), "Trimmed Means")

```

b.) Conduct a two-sided test to see if the difference in trimmed means is statistically significant.

```{r, echo = T, fig.height=3.5, fig.width=8}
N <- 10e2 - 1
results <- numeric(N)

for(i in 1:N)
{
   index <- sample(nrow(Flights), nrow(Flights[Carrier == "UA"]), replace = F)
   results[i] <- mean(Flights[index]$Delay, trim = trim.amount) - mean(Flights[-index]$Delay, trim = trim.amount)
}

p <- min(1, 2 * (sum(results[results >= observed]) + 1) / ( N + 1))
v <- p*(1 - p) / ( N + 1 )

ggplot(data.table(results)) +
   geom_histogram(aes(results, fill = ..count..), bins = 30) +
   geom_vline(xintercept = observed, col = "darkorange", linetype = 3, lwd = 1.2) +
   scale_y_continuous(labels = comma) +
   labs(title = paste0("Flight Delay Time Trimmed Mean vs Observed, p=", round(p, 5)), 
        subtitle = paste0("Observed Value: ", round(observed, 4)))
```

### 3.9

In the flight delays case study in Section 1.1,

a.) Compute the proportion of times the flights in May and in June were delayed more than 20 min.

```{r, echo = T}

delay20_month <- Flights[, .(Delay20 = sum(Delay > 20) / .N), by = Month]

pretty_kable(delay20_month, "Delayed by more than 20 min, by month")

```

Conduct a two-sided test for statistical significance.

```{r, echo = T, fig.height=3.5, fig.width=8}

observed <- delay20_month[Month == "May"]$Delay20 - delay20_month[Month == "June"]$Delay20

N <- 10e2 - 1
results <- numeric(N)

for( i in 1:N)
{
   index <- sample(nrow(Flights), nrow(Flights[Month == "May"]), replace = F)
   results[i] <- as.numeric( Flights[index, .(Delay = sum(Delay > 20) / .N)] - Flights[-index, .(Delay = sum(Delay > 20) / .N)] )
}

p <- min(1, 2 * (sum(results[results >= observed]) + 1) / ( N + 1))
v <- p*(1 - p) / ( N + 1 )

```

P-value: `r round(p, 4)`, which is statistically significant.

b.) Compute the ratio of the variances in the flight delay times in May and in June.

```{r, echo = T, fig.height=3.5, fig.width=8}

observed <- var(Flights[Month == "May"]$Delay) - var(Flights[Month == "June"]$Delay)

N <- 10e2 - 1
results <- numeric(N)

for( i in 1:N)
{
   index <- sample(nrow(Flights), nrow(Flights[Month == "May"]), replace = F)
   results[i] <- var( Flights[index, .(Delay)] ) - var( Flights[-index, .(Delay)] )
}

p <- min(1, 2 * (sum(results[results >= observed]) + 1) / ( N + 1))
v <- p*(1 - p) / ( N + 1 )

```

Is this evidence that the true ratio is not equal to 1, or could this be due to chance variability?

The variance appear to be due to random chance, so there does appear to be a stastical significance between the two months.

Conduct a two-sided test to check.

P-value: __`r p`__

### 3.10

In the black spruce case study in Section 1.10, seedlings were planted in plots that were either subject to competition (from other plants), or not.

Use the data set _Spruce_ to conduct a test to see if the mean difference is how much the seedlings grow (in height) over the corse of the study under these two treatments is stastically significant.

```{r, echo = T}
Spruce <- data.table(read.csv(paste0(data.dir, "Spruce.csv"),
                               header = T))

observed <- mean( Spruce[Competition == "NC"]$Ht.change ) - mean( Spruce[Competition == "C"]$Ht.change )

N <- 10e2 - 1
results <- numeric(N)

for(i in 1:N)
{
   index <- sample(nrow(Spruce), nrow(Spruce[Competition == "NC"]), replace = F)
   resutls <- mean( Spruce[index]$Ht.change ) - mean( Spruce[-index]$Ht.change )
}

p <- min(1, 2 * (sum(results[results >= observed]) + 1) / ( N + 1))

```

There is stastical significance in between the heights of the two groups (Competition / No-competition).

P-value: __`r p`__


### 3.11

The file _Phillies2009_ contains data from the 2009 season for the baseball team the Philadelphia Phillies.

```{r, echo = T}
Phillies <- data.table(read.csv(paste0(data.dir, "Phillies2009.csv"),
                               header = T))
```

a.) Compare the empirical distribution functions of the number of strike-outs per game (_StrikeOuts_) for games played at home and games played away (_Location_).

```{r, echo = T, fig.width=8, fig.height=3.5}

ggplot(Phillies, aes(StrikeOuts, color = Location)) +
   stat_ecdf(stat = "point") +
   labs(title = "Strike-outs / Game, by Location", y = "Percent")

```

b.) Find the mean number of strike-outs per game for the home and the away games.

```{r, echo = T}
strikeouts <- Phillies[, .(StrikeOuts = mean(StrikeOuts)), by = Location]

pretty_kable(strikeouts, "StrikeOuts by Location")

observed <- mean(strikeouts[Location == "Away"]$StrikeOuts) - mean(strikeouts[Location == "Home"]$StrikeOuts)

```
c.) Perform a permutation tests to see if the differences in means is statistically significant.

```{r, echo = T}

N <- 10e2 - 1
results <- numeric(N)

for( i in 1:N)
{
   index <- sample(nrow(Phillies), nrow(Phillies[Location == "Home"]), replace = F)
   results[i] <- mean(Phillies[index]$StrikeOuts) - mean(Phillies[-index]$StrikeOuts)
}

p <- min(1, ( sum(results >= observed) + 1) / ( N + 1) )

```

There does not appear to be a statistically significat relationship between the number of home and away strikeouts.

P-value: __`r p`__

### 3.12

In the Iowa recidivism case study in Section 1.4, offenders had originally been convicted of either a felony or misdemenor.

```{r, echo = T}
Recidivism <- data.table(read.csv(paste0(data.dir, "Recidivism.csv"),
                               header = T))
```

a.) Use R to create a table displaying the proportion of felons who recidivated and the propportion of those convictted of a misdemeanor who recidivated.

```{r, echo = T, fig.width=8, fig.height=3.5}

Recidivism[, Recidivated := is.na(Days)]

Recidivated <- Recidivism[, .(RecidPct = sum(Recidivated) / .N), by = Offense]

pretty_kable(Recidivated, "Recidivated")

```

b.) Determine whether or not the difference in recidivism proportions computed in (a) is statistically significant.

```{r, echo = T}

observed <- as.numeric( Recidivated[Offense == "Felony"]$RecidPct - Recidivated[Offense == "Misdemeanor"]$RecidPct )

N <- 10e2 - 1
results <- numeric(N)

for( i in 1:N )
{
   index <- sample(nrow(Recidivism), nrow(Recidivism[Offense == "Felony"]), replace = F)
   results[i] <- as.numeric( Recidivism[index, .(Pct = sum(Recidivated) / .N)] - Recidivism[-index, .(Pct = sum(Recidivated) / .N)] )
}

p <- ( sum(results >= observed) + 1 ) / ( N + 1 )

```

It appears there is statistical significance in the recidivism rates between felony and misdemeanor convictions.

P-value: `r p`

### 3.13

In the Iowa recidivism case study in Section 1.4, for those offenders who recidivated, we have data on the number of days until they reoffended.

For those offenders who did recidivate, determine if the difference in the mean number of days (__Days__) until recidivism between those under 25 years of age and those 25 years of age and older is statistically significant.

```{r, echo = T}

Recid.Age25 <- Recidivism[, .(RecidDays = mean(Days, na.rm = T)), by = Age25]

pretty_kable(Recid.Age25, "Days Until Recidivism by Age ( < 25 < )")

observed <- as.numeric( Recid.Age25[Age25 == "Under 25"]$RecidDays - Recid.Age25[Age25 == "Over 25"]$RecidDays)

N <- 10e2 - 1
results <- numeric(N)

for( i in 1:N )
{
   index <- sample(nrow(Recidivism), nrow(Recidivism[Age25 == "Under 25"]), replace = F)
   results[i] <- mean(Recidivism[index]$Days, na.rm = T) - mean(Recidivism[-index]$Days, na.rm = T)
}

p <- min(1, ( sum(results >= observed) + 1 ) / ( N + 1 ) )

```

There does not appear to be a statistical difference between the days until recidivism by those over/under 25 years of age.

P-value: `r p`

### 3.14

Does chocolate ice cream have more calories than vanilla ice cream? The data set __IceCream__ contains calorie information for a sample of brands of chocolate and vanilla ice cream.

```{r, echo = T}
IceCream <- data.table(read.csv(paste0(data.dir, "IceCream.csv"),
                               header = T))
```

a.) Inspect the data set, then explain why this is an example of matched pairs data.

```{r, echo = T}
pretty_kable(IceCream, "Ice Cream Data")
```

This data set is matched pairs becase there are multiple brands associated with each flavor. They are not independent samples.

b.) Compute summary statistics of the number of calories for the two flavors.

```{r, echo = T}

pretty_kable(IceCream[, .(Vanilla = mean(VanillaCalories), Chocolate = mean(ChocolateCalories))], 
             "Ice cream Calories by Flavor")

```


c.) Conduct a permutation tests to determine whether or not chocolate ice cream has, on average, more calories than vanilla ice cream.

```{r, echo = T}

diff <- IceCream$VanillaCalories - IceCream$ChocolateCalories
observed <- mean(diff)

N <- 10e2 - 1
results <- numeric(N)

for( i in 1:N )
{
   Sign <- sample(c(-1, 1), nrow(IceCream), replace = T)
   diff2 <- Sign * diff
   results[i] <- mean(diff2)
}

p <- ( sum( results <= observed ) + 1 ) / ( N + 1 )

```

The data supports the claim that chocolate ice cream has more calories than vanilla.

P-value: `r p`

### 3.15

Is there a difference in the price of groceries sold by the two retailers Target and Walmart?

The data set Groceries contains a sample of grocery items and their prices advertised on their respective web sites on one specific day.

```{r, echo = T}
Groceries <- data.table(read.csv(paste0(data.dir, "Groceries.csv"),
                               header = T))


```

a.) Inspect the data set, then explain why this is an example of matched pairs data.

```{r, echo = T}
pretty_kable(Groceries, "Target vs Walmart")
```

b.) Compute summary statistics of the prices for each store.

```{r, echo = T}

diff <- Groceries$Target - Groceries$Walmart

observed <- mean(diff)

```

Observed difference: __`r observed`__

c.) Conduct a permutation test to determine whether or not there is a difference in the mean prices.

```{r, echo = T}
N <- 10e2 - 1
results <- numeric(N)

for( i in 1:N )
{
   Sign <- sample(c(-1, 1), nrow(Groceries), replace = T)
   diff2 <- Sign * diff
   results[i] <- mean(diff2)
}

p <- min(1, 2 * ( sum(results >= observed ) + 1 ) / ( N + 1) )

```

There does not appear to be a statistical difference in the prices at the two stores.

P-value: `r p`

d.) Create a histogram of the difference in prices. 

```{r, echo = T, fig.height=5, fig.width=8}

ggplot(data.table( Product = Groceries$Product, Diff = diff)) +
   geom_bar(aes(Product, Diff, fill = Product), stat = "identity") +
   coord_flip() +
   labs(title = "Grocery Price Difference (Target vs Walmart)") +
   theme(legend.position = "none")

```

What is unusual about Quaker Oats Life cerial?

__Price difference is a multiple SD outlier.__

e.) Redo the hypothesis test without this observation.

```{r, echo = T}

diff <- Groceries[Product != "Quaker Oats Life Cereal  Original ", .(Diff = Target - Walmart ) ]$Diff

observed <- mean(diff)

N <- 10e2 - 1
results <- numeric(N)

for( i in 1:N )
{
   Sign <- sample(c(-1, 1), length(diff), replace = T)
   diff2 <- Sign * diff
   results[i] <- mean(diff2)
}

p <- min(1, 2 * ( sum(results >= observed ) + 1 ) / ( N + 1) )

```

Do you reach the same conclusion?

__No, there is a statistical difference in the prices of products at the two retailers with the outlier removed.__

P-value: `r p`

### 3.16

In the sampling version of permutation testing, the one-sided P-value is 

$\hat{P} = \frac{(X + 1)}{(N + 1)}$, where X is the number of permutation test statistics that are as large or larger than the observed test statistic.

Suppose the true P-value (for the exaustive test, conditional on the observed data) is __p__.

a.) What is the variance of $\hat{P}$?

$\mathbb{V} = p*(1 - p) / (N + 1)$

b.) What is the variance of $\hat{P}_2$ for the two-sided test (assuming that __p__ is not close to 0.5, where __p__ is the smaller true one-side P-value)?



