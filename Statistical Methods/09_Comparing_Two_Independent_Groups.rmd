---
title: ''
mainfont: Arial
fontsize: 12pt
documentclass: report
header-includes:
- \PassOptionsToPackage{table}{xcolor}
- \usepackage{caption}
- \usepackage{amssymb}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage[table]{xcolor}
- \usepackage{fancyhdr}
- \usepackage{boldline}
- \usepackage{tipa}
   \definecolor{headergrey}{HTML}{545454}
   \definecolor{msdblue}{HTML}{1C93D1}
   \pagestyle{fancy}
   \setlength\headheight{30pt}
   \rhead{\color{headergrey}\today}
   \fancyhead[L]{\color{headergrey}Moretz, Brandon}
   \fancyhead[C]{\Large\bfseries\color{headergrey}Comparing Two Independent Groups}
   \rfoot{\color{headergrey}\thepage}
   \lfoot{\color{headergrey}Chapter 9}
   \fancyfoot[C]{\rmfamily\color{headergrey}Statistical Methods}
geometry: left = 1cm, right = 1cm, top = 2cm, bottom = 3cm
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: 
    fig_caption: yes
    latex_engine: xelatex
editor_options: 
  chunk_output_type: console
---


```{r knitr_setup, include = FALSE}

# DO NOT ADD OR REVISE CODE HERE
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, dev = 'png')
options(knitr.table.format = "latex")

```

```{r report_setup, message = FALSE, warning = FALSE, include = FALSE}

library(data.table, quietly = TRUE, warn.conflicts = FALSE)

assignInNamespace("cedta.pkgEvalsUserCode", c(data.table:::cedta.pkgEvalsUserCode, "rtvs"), "data.table")

library(here, quietly = T, warn.conflicts = F)
library(ggplot2, quietly = T, warn.conflicts = F)
library(ggrepel, quietly = TRUE, warn.conflicts = FALSE)
library(ggthemes, quietly = TRUE, warn.conflicts = FALSE)
library(knitr, quietly = TRUE, warn.conflicts = FALSE)
library(kableExtra, quietly = TRUE, warn.conflicts = FALSE)
library(scales, quietly = TRUE, warn.conflicts = FALSE)
library(pander, quietly = TRUE, warn.conflicts = FALSE)
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)
library(formattable, quietly = TRUE, warn.conflicts = FALSE)
library(grid, quietly = TRUE, warn.conflicts = FALSE)
library(gridExtra, quietly = TRUE, warn.conflicts = FALSE)
library(WRS, quietly = TRUE, warn.conflicts = FALSE)

options(tinytex.verbose = TRUE)
suppressMessages(library("tidyverse"))

pretty_kable <- function(data, title, dig = 2) {
  kable(data, caption = title, digits = dig) %>%
    kable_styling(bootstrap_options = c("striped", "hover")) %>%
      kableExtra::kable_styling(latex_options = "hold_position")
}

theme_set(theme_light())

# Theme Overrides
theme_update(axis.text.x = element_text(size = 10),
             axis.text.y = element_text(size = 10),
             plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "darkgreen"),
             axis.title = element_text(face = "bold", size = 12, colour = "steelblue4"),
             plot.subtitle = element_text(face = "bold", size = 8, colour = "darkred"),
             legend.title = element_text(size = 12, color = "darkred", face = "bold"),
             legend.position = "right", legend.title.align=0.5,
             panel.border = element_rect(linetype = "solid", 
                                         colour = "lightgray"), 
             plot.margin = unit(c( 0.1, 0.1, 0.1, 0.1), "inches"))

data.dir <- paste0(here::here(), "/datasets/")

```

```{r pander_setup, include = FALSE}

knitr::opts_chunk$set(comment = NA)

panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)

```

### Chapter 9

#### 9.1

Suppose that the sample means and variances are $\bar{X}_1 = 15, \bar{X}_2 = 12, s^2_1 = 8, s^2_2 = 24, n_1 = 20, n_2 = 10$

Verify that $s^2_p = 13.14, T = 2.14$ and that Student's T test rejects the hypothesis of equal means with $\alpha = 0.05$.

```{r, echo = T}
xbar1 <- 15; xbar2 <- 12; s1sq <- 8; s2sq <- 24
n1 <- 20; n2 <- 10
alpha <- 0.05

variance <- ( (n1 - 1)*s1sq + (n2 - 1)*s2sq ) / ( n1 + n2 - 2 )
variance

t.stat <- (xbar1 - xbar2) / sqrt( variance*(1/n1 + 1/n2) )
t.stat

crit <- qt(alpha/2, df = n1 + n2 - 2)

ifelse(abs(t.stat) >= crit, "Reject Null", "Fail to Reject")
```

#### 9.2

For two independent groups of subjects, $\bar{X}_1 = 45, \bar{X}_2 = 36, s^2_1 = 4, s^2_2 = 16, n_1 = 20, n_2 = 30$. Assume that the population variances of the two groups are equal and verify that the estimate of this common variance is 11.25.

```{r, echo = T}
xbar1 <- 45; xbar2 <- 36; s1sq <- 4; s2sq <- 16
n1 <- 20; n2 <- 30

variance <- ( (n1 - 1)*s1sq + (n2 - 1)*s2sq ) / ( n1 + n2 - 2)

stopifnot(variance == 11.25)
```

#### 9.3

Still assuming equal variances, test the hypothesis of equal means using Student's T test and the data in the last exercise. Use $\alpha = 0.05$

```{r, echo = T}
alpha <- 0.05

t.stat <- (xbar1 - xbar2 ) / sqrt( variance * (1/n1 + 1/n2) )

crit <- qt(alpha/2, df = (n1 + n2 - 2))

ifelse(abs(t.stat) >= crit, "Reject null", "Fail to Reject")
```

#### 9.4

Repeat the last problem, only use Welch's test for comparing means.

```{r, echo = T}
w.stat <- (xbar1 - xbar2) / sqrt(s1sq/n1 + s2sq/n2)

q1 <- s1sq/n1; q2 <- s2sq/n2
df <- (q1 + q2)^2 / ( q1^2/(n1 - 1) + q2^2/(n2 - 1) )

crit <- qt(1 - alpha/2, df)

ifelse(abs(w.stat) >= crit, "Reject Null", "Fail to Reject")
```

#### 9.5

Comparing the results for the last two problems, what do they suggest regarding the power of Welch's test compared to STudent's T test when the sample variances differ sufficiently.

```{r, echo = T}
t.stat
w.stat
```

_Roughtly, the W statistic has more power because it is larger than the T statistic._

#### 9.6

For two independent groups $\bar{X}_1 = 86, \bar{X}_2 = 80, s^2_1 = s^2_2 = 25, n_1 = n_2 = 20$. Assume that the population variances of the two groups are equal and verify that Student's T rejects with $\alpha = 0.01$.

```{r, echo = T}
xbar1 <- 86; xbar2 <- 80; s1sq <- s2sq <- 25
n1 <- n2 <- 20; alpha <- 0.01

t.stat <- (xbar1 - xbar2) / sqrt(2 * s1sq/n1 )

crit <- qt(alpha/2, df = n1 + n2 - 2)

ifelse(abs(t.stat) >= crit, "Reject", "Fail to Reject")
```

#### 9.7

Repeat the last exercise using Welch's method.

```{r, echo = T}

w.stat <- (xbar1 - xbar2) / sqrt( 2 * s1sq/n1 )

q1 <- s1sq/n1; q2 <- s2sq/n2

df <- (q1 + q2)^2 / ( q1^2/(n1 - 1) + q2^2/(n2 - 1))

crit <- qt(alpha/2, df = 38)

ifelse(abs(w.stat) >= crit, "Reject", "Fail to Reject")
```

#### 9.8

Comparing the results of the last two problems, what do they suggest about using Student's T versus Welch's method when the sample variances are approximately equal?

```{r, echo = T}
t.stat
w.stat
```

_With equal sample variances, Student's T and Welch give exactly the same result, suggesting that when the sample variances are approximately equal, the choice between T and W makes little difference._

#### 9.9

For $\bar{X}_1 = 10, \bar{X}_2 = 5, s^2_1 = 21, s^2_2 = 29, n_1 = n_2 = 16$, compute a 0.95 conffidence interval for the difference between the means using Welch's method and state whether a decision can be made about which group has the larger popluation mean.

```{r, echo = T}
xbar1 <- 10; xbar2 <- 5; s1sq <- 21; s2sq <- 29
n1 <- n2 <- 16; alpha <- 0.05

q1 <- s1sq/n1; q2 <- s2sq/n2
df <- (q1 + q2)^2 / (q1^2 / (n1 - 1) + q2^2 / (n2 -1) )

variance <- sqrt(s1sq/n1 + s2sq/n2)

(xbar1 - xbar2) + qt(c(Lower = alpha/2, Upper = 1 - alpha/2), df)*variance
```

#### 9.10

Repeat the last problem, only use Student's T instead.

```{r, echo = T}
sqp <- (s1sq+s2sq) / 2

(xbar1 - xbar2) + qt(c(Lower = alpha/2, Upper = 1 - alpha/2), n1 + n2 - 2) * sqrt(sqp * (1/n1 + 1/n2))
```

#### 9.11

Two methods for training accountants are to be compared. Students are randomly assigned to one of the two methods. At the end of the course, each student is asked to prepare a tax return for the same individual. The amounts of the refund reported by the students are:

M1: 132, 204, 603, 50, 125, 90, 185, 134
M2: 92, -42, 121, 63, 182, 101, 294, 36

Using Welch's test would you conclude that the methods differ in terms of the average return? Use $\alpha = 0.05$.

```{r, echo = T}
dat <- data.table(
   M1 = c(132, 204, 603, 50, 125, 90, 185, 134),
   M2 = c(92, -42, 121, 63, 182, 101, 294, 36))

t.test(dat$M1, dat$M2, conf.level = .95)
```

The p-value is 0.258, so no, fail to reject and make no decision about which group has the larger population mean.

#### 9.12

Responses to stress are govered by the hypothalamus. Imagine you have two randomly sampled groups of individuals between the ages of 60 and 65. The first shows signs of heart disease and the other does not. You want to determine whether the groups differ in terms of some measure associated with the hypothalamus. For the first group of subjects with no heart disease, the measures are:

11.1, 12.2, 15.5, 17.6, 13.0, 7.5, 9.1, 6.6, 9.5, 18.0, 12.6

For the other group with heart disease, the kmeasures are:

18.2, 14.1, 13.8, 12.1, 34.1, 12.0, 14.1, 14.5, 12.6, 12.5, 19.8, 13.4, 16.8, 14.1, 12.9

Determine whether the groups differ based on Welch's test. Use $\alpha = 0.05$.

```{r, echo = T}
dat <- data.table(
   M1 = c(11.1, 12.2, 15.5, 17.6, 13.0, 7.5, 9.1, 6.6, 9.5, 18.0, 12.6),
   M2 = c(18.2, 14.1, 13.8, 12.1, 34.1, 12.0, 14.1, 14.5, 12.6, 12.5, 19.8, 13.4, 16.8, 14.1, 12.9))

t.test(dat$M1, dat$M2, conf.level = .95)
```

_Fail to reject because the p-value is greater than 0.05 and make no decision about which group has the larger population mean._

#### 9.13

The 0.95 confidence interval for the difference between the means, using Student's T, is (2.2, 20.5).

What are the practical concerns with this confidence interval?

_The actual probability coverage could differ substantially from 0.95._

#### 9.14

For the first of two binomial distributions, there are 15 successes amoung 24 observations. For the second, there are 23 successes among 42 observations.

Test $H_0 : p_1 = p_2$ with a Type I error probability of 0.05 using the Storer-Kim method, followed by Beal's method.

Note the p-values and comment on what this suggests in terms of power.

```{r, echo = T}
# Storer-Kim
twobinom(15, 24, 23, 42)
# Beal's
twobicipv(15, 24, 23, 42)
```

_In this particular case, the p-value returned by Beal's method is substantially larger than the p-value returned by the Storer Kim method, suggesting that generally the Storer Kim method will have more power._

#### 9.15

A film producer wants to know which of two versions of a particular scene is more likely to be viewed as disturbing. A group of 98 individuals views the first version and 20 say that it is disturbing. Another group sees the second version and 30 of 70 people say that it is disturbing.

What is the probability these two probabilities are equal?

```{r, echo = T}
# Storer-Kim
twobinom(20, 98, 30, 70)

# Beal's
twobicipv(20, 98, 30, 70)
```

Both reject, again Storer Kim method has more power.

#### 9.16

It is found that amoung 121 individuals who take a training program on investing in commodities, 20 make money during the next year and the rest do not. With another training program, 15 of 80 make money.

Test the hypothesis that the probability of making money is the same for both training programs with a Type I error probability of 0.05.

```{r, echo = T}
p1 <- 20/121; p2 <- 15/80
Z <- (p1-p2)/sqrt(p1*(1-p1)/121 + p2*(1-p2)/80)
crit <- qnorm(0.05/2)
ifelse(abs(Z) >= crit, "Reject Null", "Fail To Reject")
```

#### 9.17

In a study dealing with violence between factions in the Middle East, one goal was to compare measures of depression for two groups of young males. In the first group, no family member was wounded or killed by someone belonging to the opposite faction, and the measures were:

+ 22, 23, 12, 11, 30, 22, 7, 42, 24, 33, 28, 19, 4, 34, 15, 26, 50, 27, 20, 30, 14, 42

The second group considted of young males who had a family member killed or wounded. The observed values were:

+ 17, 22, 16, 16, 14, 29, 20, 20, 19, 14, 10, 8, 26, 9, 14, 17, 21, 16, 14, 11, 14, 11, 29, 13, 4, 16, 16, 7, 21

Test the hypothesis of equal means with Student's T test and $\alpha = 0.05$, and compute a .95 confidence interval.

```{r, echo = T}
dat <- data.table(
   X1 = c(22, 23, 12, 11, 30, 22, 7, 42, 24, 33, 28, 19, 4, 34, 15, 26, 50, 27, 20, 30, 14, 42),
   X2 = c(17, 22, 16, 16, 14, 29, 20, 20, 19, 14, 10, 8, 26, 9, 14, 17, 21, 16, 14, 11, 14, 11, 29, 13, 4, 16, 16, 7, 21)
)

t.test(dat$X1, dat$X2)
t.test(dat$X1, dat$X2, var.equal = T)
```

_Student's T yields a shorter confidence interval, but the confidence interval based on Student's T can be less accurate compared to the confidence interval based on Welch's method._

#### 9.18

For the data in the last problem, the difference between the medians is -7.5 and the corresponding McKean-Schrader estimate of the standard error is $\sqrt(S^2_1 + S^2_2) = 3.93$.

Verify that you do not reject the hypothesis of equal medians with $\alpha = 0.05$

```{r, echo = T}
msmed(dat$X1, dat$X2)
```

#### 9.19

Using the data in Excercise 17, use a percentile bootstrap method to compare the medians. Note that the p-value is 0.01. This is in contrast to the result in Exercise 18, where the hypothesis of equal medians is not rejected at the 0.05 level.

```{r, echo = T}
medpb2(dat$X1, dat$X2)
```

_The p-value indicates that the hypothesis of equal medians would be rejected at the 0.01 level, in contrast to the method based on theMcKean-Schrader estimator, which has a p-value equal to 0.057._

#### 9.20

Repeat the analysis of the sexual attitude data, the second example in Section 9.10.2, only now use _twobinom_ and _twobicipv_.

```{r, echo = T}
twobinom(49,105,101,156)

twobicipv(49,105,101,156)
```

#### 9.21

Does the consumption of alcohol limit our attention span? An article in the July 10, 2006 Los Angeles Times described a study conducted at the University of Washington where 23 people were given enough alcohol to reach a BAC of 0.04%. A second group of 23 people drank no alcohol. The researchers then showed amembers of both groups a 25-second video clip in which two teams passed a ball back and forth and asked them to count the number of times one team passed the ball. During the clip, a person in a gorilla suit walks through the crowd, thumps its chest, and walks off.

Researchers found that 11 of the 23 participants in the control group saw the gorilla, compared to 10 in the alcohol group.

Verify that you do not reject the null hypothesis that the two groups have the same probability of seeing the gorilla using the Storer-Kim method with $\alpha = 0.05$.

```{r, echo = T}
twobinom(11,23,10,23)
```

#### 9.22

Despite any problems it might have, summarize how you would justify using Student's T test to compare two indepentent groups.

_Student's T controls the Type I error probability when comparing identical distributions. It is possible that Student's T accurately detects a difference in the distributions that might be missed by other methods._

#### 9.23

Summarize any practical conccerns about Student's T test and comment on how they might be addressed.

_In terms of understanding the nature of any difference that might exist, Student's T can be highly inaccurate in some situations. Confidence intervals for the difference between the means can be inaccurate when distributions differ. Problems with heteroscedasticity can be reduced by using a method that allows heteroscedasticity, such as Welch's test or a bootstrap-t method. But inaccurate confidence intervals, as well as relatively low power due to outliers, are always a concern when using means. Other methods might have substantially more power, such as techniques based on the median or 20% trimmed mean. Even with discrete distributions where outliers are rare, the methods in Section 9.11 might have more power. The only safe way to determine whether alternative methods make a difference is to try them._

#### 9.24

Summarize the relative merits of comparing groups with medians.

_The median better reflects the typical value for skewed distributions, it can have relatively high power when outliers are common. Accurate confidence intervals can be computed over a fairly broad range of situations, much broader than methods based on means. But for skewed distributions, it is possible that means have more power, even when the Type I error probability is controlled reasonably well, because the difference between the means might be larger. As noted in Chapter 2, there are situations where the mean can be argued to be a better measure of location. Also, when dealing with distributions that have light tails (outliers are relatively uncommon), the mean or some smaller amount of trimming can have a smaller standard error._

#### 9.25

For each of two independent groups, 1,000 bootstrap stamples are generated and it is found that there are 10 instances where the bootstrap sample trimmed mean for the first group is less than the bootstrap sample trimmed mean for the second. There are two instances where the bootstrap sample trimmed means are equal. Determine a p-value when testing the hypothesis of equal population trimmed means.

B = 1000, A = 10, C = 2,
Q = (A + 0:5C)=B = 0:01 + 0:5(0:002) = 0:011. Set P equal to Q or 1 Q, whichever is smaller, 
so P = 0:011 and the p-value is 2P = 2(0:011) = 0:022

#### 9.26

Repeat the analysis of Salk's data in section 9.1.6 using Welch's method.

```{r, echo = T}
salk <- data.table::fread(paste0(data.dir, "salk_dat.txt"), fill = T)

t.test(salk[,1],salk[,2])
```

#### 9.27

For the self-awareness data, apply Yuen's method with 20% trimming.

```{r, echo = T}
dana <- data.table::fread(paste0(data.dir, "dana_dat.txt"), fill = T)

yuen(dana[,1],dana[,2])
```

#### 9.28

Duplicate the results for shoulder pain.

```{r, echo = T}
g1=c(2, 4, 4, 2, 2, 2, 4, 3, 2, 4, 2, 3, 2, 4, 3, 2, 2, 3, 5, 5, 2, 2)
g2=c(5, 1, 4, 4, 2, 3, 3, 1, 1, 1, 1, 2, 2, 1, 1, 5, 3, 5)
disc2com(g1,g2)
```
