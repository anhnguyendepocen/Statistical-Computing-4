---
title: ''
mainfont: Arial
fontsize: 12pt
documentclass: report
header-includes:
- \PassOptionsToPackage{table}{xcolor}
- \usepackage{caption}
- \usepackage{amssymb}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage[table]{xcolor}
- \usepackage{fancyhdr}
- \usepackage{boldline}
- \usepackage{tipa}
   \definecolor{headergrey}{HTML}{545454}
   \definecolor{msdblue}{HTML}{1C93D1}
   \pagestyle{fancy}
   \setlength\headheight{30pt}
   \rhead{\color{headergrey}\today}
   \fancyhead[L]{\color{headergrey}Moretz, Brandon}
   \fancyhead[C]{\Large\bfseries\color{headergrey}Hypothesis Testing}
   \rfoot{\color{headergrey}\thepage}
   \lfoot{\color{headergrey}Chapter 7}
   \fancyfoot[C]{\rmfamily\color{headergrey}Statistical Methods}
geometry: left = 1cm, right = 1cm, top = 2cm, bottom = 3cm
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
editor_options: 
  chunk_output_type: console
---


```{r knitr_setup, include = FALSE}

# DO NOT ADD OR REVISE CODE HERE
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, dev = 'png')
options(knitr.table.format = "latex")

```

```{r report_setup, message = FALSE, warning = FALSE, include = FALSE}

library(data.table, quietly = TRUE, warn.conflicts = FALSE)

assignInNamespace("cedta.pkgEvalsUserCode", c(data.table:::cedta.pkgEvalsUserCode, "rtvs"), "data.table")

library(here, quietly = T, warn.conflicts = F)
library(ggplot2, quietly = T, warn.conflicts = F)
library(ggrepel, quietly = TRUE, warn.conflicts = FALSE)
library(ggthemes, quietly = TRUE, warn.conflicts = FALSE)
library(knitr, quietly = TRUE, warn.conflicts = FALSE)
library(kableExtra, quietly = TRUE, warn.conflicts = FALSE)
library(scales, quietly = TRUE, warn.conflicts = FALSE)
library(pander, quietly = TRUE, warn.conflicts = FALSE)
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)
library(formattable, quietly = TRUE, warn.conflicts = FALSE)
library(grid, quietly = TRUE, warn.conflicts = FALSE)
library(gridExtra, quietly = TRUE, warn.conflicts = FALSE)
library(WRS, quietly = TRUE, warn.conflicts = FALSE)

options(tinytex.verbose = TRUE)
suppressMessages(library("tidyverse"))

pretty_kable <- function(data, title, dig = 2) {
  kable(data, caption = title, digits = dig) %>%
    kable_styling(bootstrap_options = c("striped", "hover")) %>%
      kableExtra::kable_styling(latex_options = "hold_position")
}

theme_set(theme_light())

# Theme Overrides
theme_update(axis.text.x = element_text(size = 10),
             axis.text.y = element_text(size = 10),
             plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "darkgreen"),
             axis.title = element_text(face = "bold", size = 12, colour = "steelblue4"),
             plot.subtitle = element_text(face = "bold", size = 8, colour = "darkred"),
             legend.title = element_text(size = 12, color = "darkred", face = "bold"),
             legend.position = "right", legend.title.align=0.5,
             panel.border = element_rect(linetype = "solid", 
                                         colour = "lightgray"), 
             plot.margin = unit(c( 0.1, 0.1, 0.1, 0.1), "inches"))

data.dir <- paste0(here::here(), "/datasets/")
```

```{r pander_setup, include = FALSE}

knitr::opts_chunk$set(comment = NA)

panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)

```

#### Chapter 7

### 7.1

Given that $\bar{X} = 78, \sigma^2 =25, n = 10, \alpha = 0.05$ test $H_0 : \mu \ge 80$, assuming that observations are randomly sampled from a normal distribution.

```{r, echo = T}
xbar <- 78; var <- 25; n <- 10
alpha <- 0.05; h0 <- 80

# greater than = left tail test

crit <- qnorm(alpha)

Z <- sqrt(n) * (xbar - h0) / sqrt( var )

ifelse(Z < crit, "Reject the null", "Cannot reject null")
```

### 7.2

Repeat the previous exercise, but test $H_0 : \mu = 80$

```{r, echo = T}

# equals = two-tailed test

crit <- qnorm(alpha/2)

Z <- sqrt(n) * (xbar - h0) / sqrt( var )

ifelse(Z < crit || crit > Z, "Reject the null", "Cannot reject the null")

```

### 7.3

For the data in Exercise 1, compute a 0.95 confidence interval and verify that this interval is consistent with y our decision about whether to reject the null hypothesis $H_0 : \mu = 80$.

```{r, echo = T}

xbar + qnorm(c(alpha/2, 1 - alpha/2)) * sqrt( var / n )
      
```

_80_ is in the confidence interval, so fail to reject.

### 7.4

For exercise 1, determine the p-value.

```{r, echo = T}
pnorm(Z)
```

### 7.5

For exercise 2, determine the p-value.

```{r, echo = T}
2 * (1 - pnorm(Z, lower.tail = F))
```

### 7.6

Given that $\bar{X} = 120, \sigma = 5, n = 49, \alpha = 0.05$, test $H_0 : \mu \ge 130$, assuming that observations are randomly sampled from a normal distribution.

```{r, echo = T}
xbar <- 120; sigma <- 5; n <- 49
alpha <- 0.05; h0 <- 130

crit <- qnorm(alpha)

Z <- sqrt(n) * (xbar - h0) / sigma

ifelse( Z < crit, "Reject null hypothesis", "Cannot reject null")
```

### 7.7

Repeat the previous exercise but test $H_0 : \mu = 130$.

```{r, echo = T}
h0 <- 130

# two tailed test
crit <- qnorm(c(alpha/2, 1 - alpha/2))

ifelse(Z < crit[1] || Z > crit[2], "Reject null hypothesis", "Cannot Reject Null")
```

### 7.8

For the previous exercise, compute a 0.95 confidence interval and compare the result with your decision about whether to reject $H_0$.

```{r, echo = T}
xbar + qnorm(c(Lower = alpha/2, Upper = 1 - alpha/2)) * sigma/sqrt(n)
```

130 is not in the confidence region, reject null-hypothesis.

### 7.9

If $\bar{X} = 23$ and $\alpha = 0.025$, can you make a decision about whether to reject $H_0 : \mu \le 25$ without knowing $\sigma$?

_Yes, the hypothesis is consistent with the sample mean._

### 7.10

An electronics firm mass-produces a component for which there is a standard measure of quality. Based on testing vast numbers of these components, the company has found that the average quality is $\mu = 232, \sigma = 4$.

However, in recent years, the quality has not been checked, so management asks you to check their claim with the goal of being reasonable certain that an average quality of less than 232 can be ruled out. That is, assume that the quality is poor and in fact less than 232 with the goal of empirically establishing that this assumption is unlikely.

You get $\bar{X} = 240$ based on a sample of $n = 25$ components, and you want the probability of a Type I error to be less than 0.01.

State the null hypothesis and perform the appropriate test, assuming normality.

#### Hypothesis:

$H_0 : \mu \le 232$

$H_A : \mu \ge 232$

```{r, echo = T}
xbar <- 240; sigma <- 4; n <- 25
alpha <- 0.01; h0 <- 232

# less than = upper-tailed test

crit <- qnorm(1 - alpha)

Z <- sqrt(n) * ( xbar - h0 ) / sigma

ifelse(Z > crit, "Reject the null", "Cannot reject the null")
```

### 7.11

An antipollution device for cars is claimed to have an average effectiveness of exactly 546. Based on a test of 20 such devices, you find that $\bar{X} = 565$.

Assuming normality and that $\sigma = 40$, would you rule out the claim with a Type I error probability of 0.05?

```{r, echo = T}
xbar <- 565; sigma <- 40; n <- 20
alpha <- 0.05; h0 <- 546

# equality = two tailed

crit <- qnorm(c(alpha/2, 1 - alpha/2))

Z <- sqrt(n) * (xbar - h0) / sigma

ifelse(Z < crit[1] || Z > crit[2], "Reject the null", "Cannot reject the null")
```

### 7.12

Comment on the relative merits of using a 0.95 confidence interval for addressing the effectiveness of the antipollution device in the previous exercise rather than test the hypothesis: $H_0 : \mu = 232$

```{r, echo = T}
xbar + qnorm(c(alpha/2, 1 - alpha/2)) * sigma/sqrt(n)

2 * ( 1 - pnorm(Z) )
```

The hypothesised value doesn't fall within the confidence interval, however the formalized test gives us a degree of strength on which we can reject the null. Here our p-value is .03, so we reject with slight confidence.

\newpage

### 7.13

For $n = 25, \alpha = 0.01, \sigma = 5, H_0 : \mu \ge 60$, verify that power is .95 when $\mu = 56$

```{r, echo = T}

mu <- 56; sigma <- 5; n <- 25
alpha <- 0.01; h0 <- 60

# is mu greater than 60? gt = lower tail test

crit <- qnorm(alpha)

Z <- sqrt(n) * ( mu - h0) / sigma

pnorm(crit - Z) # power
```

### 7.14

For $n = 36, \alpha = 0.025, \sigma = 8, H_0 : \mu \le 100$, verify that power is .61 when $\mu = 103$

```{r, echo = T}
mu <- 103; sigma <- 8; n <- 36
alpha <- 0.025; h0 <- 100

# less than, upper tailed test

crit <- qnorm(alpha, lower.tail = F)

Z <- sqrt(n) * (mu - h0) / sigma

ifelse( Z < crit, "Reject null", "Cannot reject null")

pnorm(crit - Z, lower.tail = F) # power
```

\newpage

### 7.15

For $n = 49, \alpha = 0.05, \sigma = 10, H_0 : \mu = 50$, verify that power is approximately .56 when $\mu = 47$

```{r, echo = T}
mu <- 47; sigma <- 10; n <- 49
alpha <- 0.05; h0 <- 50

# mu = 50? two-tailed test

crit <- qnorm(c(Lower = alpha/2, Upper = 1 - alpha/2))

Z <- sqrt(n) * (mu - h0) / sigma

ifelse( Z < crit[1] || Z > crit[2], "Reject null hypothesis", "Cannot reject null")

as.vector(pnorm(crit[1] - Z) + pnorm(crit[2] - Z, lower.tail = F)) # power
```

### 7.16

A manufacturer of medication for migraine headaches knows that their product can damage the stomach if taken too often. Imagine that by a standard measuring process, the average damage is $\mu = 48$. A modification of their product is being contemplated, and based on 10 trials, it is found that $\bar{X} = 46$. Assuming $\sigma = 5$ they test $H_0 : \mu \ge 48$, the idea being that if they reject, there is convincing evidence that the average amount of damage is less than 48. Then,

$Z = \frac{46 - 48}{5/\sqrt10} = -1.3$

With $\alpha = 0.05$, the critical value is -1.645, so they do not reject Z is less than the critical value.

What might be wrong with accepting $H_0$ and concluding that the modificaiton results in an average amount of damage greater than or equal to 48?

```{r, echo = T}
mu <- 46; sigma <- 5; n <- 10
alpha <- 0.05; h0 <- 48

crit <- qnorm(alpha)

Z <- (mu - h0) / sigma * sqrt(n)

pnorm(crit - Z)
```

Low power in the test, might commit a Type II error.

### 7.17

For the previous exercise, verify that the power is 0.35 if $\mu = 46$

```{r, echo = T}
pnorm(crit - Z)
```

### 7.18

The previous exercise indicates that power is relatively low with only $n = 10$ observations. Imagine that you want power to be at least .8. One way of getting more power is to increase the sample size, _n_.

Verify that for sample sizes of 20, 30 and 40, power is .56, 0.71, and .81, respectively.

```{r, echo = T}
n <- c(20, 30, 40)

Z <- (mu - h0) / sigma * sqrt(n)

pnorm(crit - Z)
```

### 7.19

For the previous exercise, rather than increase the sample size, what else might you do to increase the power? What is the negative consequence for this strategy?

_An alternative to increasing the sample size is to increase alpha, which will increase the probability of a type I error._

### 7.20

Given the following values for $\bar{X}$ and s:

test the hypothesis $H_0 : \mu = 42, \alpha = 0.05, n = 25$

a.) $\bar{X} = 44, s = 10$

```{r, echo = T}
xbar <- 44; s <- 10; n <- 25
alpha <- 0.05; h0 <- 42

crit <- qt(c(alpha/2, 1 - alpha/2), df = n - 1)

Z <- (xbar - h0) / s * sqrt(n)

ifelse(Z < crit[1] || Z > crit[2], "Reject the null", "Cannot reject the null")
```

b.) $\bar{X} = 43, s = 10$

```{r, echo = T}
xbar <- 43; s <- 10; n <- 25
alpha <- 0.05; h0 <- 42

crit <- qt(c(alpha/2, 1 - alpha/2), df = n - 1)

Z <- (xbar - h0) / s * sqrt(n)

ifelse(Z < crit[1] || Z > crit[2], "Reject the null", "Cannot reject the null")
```

c.) $\bar{X} = 43, s = 2$

```{r, echo = T}
xbar <- 43; s <- 2; n <- 25
alpha <- 0.05; h0 <- 42

crit <- qt(c(alpha/2, 1 - alpha/2), df = n - 1)

Z <- (xbar - h0) / s * sqrt(n)

ifelse(Z < crit[1] || Z > crit[2], "Reject the null", "Cannot reject the null")
```

### 7.21

For part b of the last exercise, you fail to reject but you reject for the situation in part c. What does this illustrate about power?

_Power is higher with smaller variance._

### 7.22

Test the hypothesis $H_0 : \mu \le 42$ with $\alpha = 0.05, n = 16$ for the following values of $\bar{X}$ and s:

a.) $\bar{X} = 44, s = 10$

```{r, echo = T}
xbar <- 44; s <- 10; n <- 16
alpha <- 0.05; h0 <- 42

# less than, upper tailed test
crit <- qt(alpha, df = n - 1, lower.tail = F)

Tval <- (xbar - h0) / s * sqrt(n)

ifelse( Tval > crit, "reject the null", "fail to reject")
```

b.) $\bar{X} = 43, s = 10$

```{r, echo = T}
xbar <- 43; s <- 10

Tval <- (xbar - h0) / s * sqrt(n)

ifelse( Tval > crit, "reject the null", "fail to reject")
```

c.) $\bar{X} = 43, s = 2$

```{r, echo = T}
xbar <- 43; s <- 2

Tval <- (xbar - h0) / s * sqrt(n)

ifelse(Tval > crit, "reject the null", "fail to reject")
```

### 7.23

Repeat the previous for $H_0 : \mu \ge 42$

a.) $\bar{X} = 44, s = 10$

```{r, echo = T}
xbar <- 44; s <- 10
h0 <- 42

# greater than, lower tailed test
crit <- qt(alpha, df = n - 1)

Tval <- (xbar - h0) / s * sqrt(n)

ifelse( Tval < crit, "reject the null", "fail to reject null")
```

b.) $\bar{X} = 43, s = 10$

```{r, echo = T}
xbar <- 43; s <- 10

Tval <- (xbar - h0) / s * sqrt(n)

ifelse( Tval < crit, "reject the null", "fail to reject null")
```

c.) $\bar{X} = 43, s = 2$

```{r, echo = T}
xbar <- 43; s <- 2

Tval <- (xbar - h0) / s * sqrt(n)

ifelse( Tval < crit, "reject the null", "fail to reject null")
```

### 7.24

A company claims that on average, when their toothpaste is used, 45% of all bacteria related to gingivitus is killed.

For 10 individuals, it is found that the percentages of bacteria killed are 38, 44, 62, 72, 43, 40, 43, 42, 39, 41.

The mean and standard deviation of these values are $\bar{X} = 46.4, s = 11.27$, respectively.

Assuming normality, test the hypothesis that the average percentage is 45 with $\alpha = 0.05$

```{r, echo = T}
x <- c(38, 44, 62, 72, 43, 40, 43, 42, 39, 41)

xbar <- mean(x); s <- sd(x); n <- length(x)
alpha <- 0.05; h0 <- 45

crit <- qt(1 - alpha/2, df = n - 1)

Tval <- (xbar - h0) / s * sqrt(n)

ifelse(abs(Tval) > crit, "Reject the null", "Fail to reject the null")

pt(Tval, df = n - 1) # p-value
```

\newpage

### 7.25

A portion of a study by Wechsler (1958) reports that for 100 males taking the Wechsler Adult Intelligent Scale (WAIS), the sample mean and variance on picture completion are $\bar{X} = 9.79$ and $s = 2.72$, respectively.

Test the hypothesis $H_0 : \mu \ge 10.5, \alpha = 0.025$

```{r, echo = T}
xbar <- 9.79; s <- 2.72; n <- 100
alpha <- 0.025; h0 <- 10.5

crit <- qt(alpha, df = n - 1)

Tval <- (xbar - h0) / s * sqrt(n)

ifelse(Tval < crit, "reject the null", "fail to reject")

pt(Tval, df = n - 1) # p-value
```

### 7.26

Given that $n = 16, \bar{X} = 40, and s = 4$, test that $H_0 : \mu \le 38, \alpha = 0.01$

```{r, echo = T}
xbar <- 40; s <- 4; n <- 16
alpha <- 0.01; h0 <- 38

crit <- qt(alpha, df = n - 1, lower.tail = F)

Tval <- (xbar - h0) / s * sqrt(n)

ifelse(Tval > crit, "Reject null", "Fail to reject null")

pt(Tval, df = n - 1)
```

### 7.27

Given that $n = 9, \bar{X} = 33, s = 4$ test $H_0 : \mu = 32, \alpha = 0.05$

```{r, echo = T}
xbar <- 33; s <- 4; n <- 9
alpha <- 0.05; h0 <- 32

crit <- qt(1 - alpha/2, df = n - 1)

Tval <- (xbar - h0) / s * sqrt(n)

ifelse(abs(Tval) > crit, "Reject null", "Cannot reject null")
```

### 7.28

An engineer believes it takes an average of 150 man-hours to assemble a portion of an automobile. As a check, the time to assemble 10 such parts was ascertained, yielding $\bar{X} = 146, s = 2.5$.

Test the engineer's belief with $\alpha = 0.05$

```{r, echo = T}
xbar <- 146; s <- 2.5; n <- 10
alpha <- 0.05; h0 <- 150

crit <- qt(1 - alpha/2, df = n - 1)

Tval <- (xbar - h0) / s * sqrt(n)

ifelse(abs(Tval) > crit, "Reject the null", "Fail to Reject")
```

### 7.29

In a study of court administration, the following times to disposition were determined for 20 cases and found to be:

42, 90, 84, 87, 119, 95, 86, 99, 93, 92, 121, 71, 66, 98, 79, 102, 60, 112, 105, 98

Test the hypothesis that the average time to disposition is less than or equal to 80 at $\alpha = 0.01$.

```{r, echo = T}
x <- c(42, 90, 84, 87, 119, 95, 86, 99, 93, 92, 121, 71, 66, 98, 79, 102, 60, 112, 105, 98)

xbar <- mean(x); s <- sd(x); n <- length(x)
alpha <- 0.01; h0 <- 80

crit <- qt(alpha, df = n - 1, lower.tail = F)

Tval <- (xbar - h0) / s * sqrt(n)

ifelse(Tval > crit, "Reject the null", "Cannot reject the null")

pt(Tval, df = n - 1, lower.tail = F) # p-value

```

Or, simply:

```{r, echo = T}
t.test(x, alternative = 'greater', conf.level = 1 - alpha, mu = h0)
```

### 7.30

Assuming 20% trimming, test the hypothesis $H_0 : \mu = 42, \alpha = 0.05, n = 20$ given the following values for $\bar{X}_t$ and $s_w$:

a.) $\bar{X}_t = 44, s_w = 9$ 

```{r, echo = T}
xbar <- 44; s <- 9; n <- 20
alpha <- 0.05; h0 <- 42

g <- floor(.2*n)

df <- n - g*2 - 1

crit <- qt(1 - alpha/s, df)

Tval <- .6 * (xbar - h0) / s * sqrt(n)

ifelse(abs(Tval) > crit, "Reject the null", "Cannot reject null")
```

b.) $\bar{X}_t = 43, s_w = 9$

```{r, echo = T}
xbar <- 43; s <- 9;

Tval <- .6 * (xbar - h0) / s * sqrt(n)

ifelse(abs(Tval) > crit, "Reject the null", "Cannot reject null")
```

c.) $\bar{X}_t = 43, s_w = 3$

```{r, echo = T}
xbar <- 43; s <- 3;

Tval <- .6 * (xbar - h0) / s * sqrt(n)

ifelse(abs(Tval) > crit, "Reject the null", "Cannot reject null")
```

### 7.31

Repeat the previous exercise, only test the hypothesis $H_0 : \mu_t \le 42, \alpha = 0.05, n = 16$

a.) $\bar{X}_t = 44, s_w = 9$

```{r, echo = T}
xbar <- 44; s <- 9; n <- 16
alpha <- 0.05

g <- floor(.2*n)

df <- n - g*2 - 1

crit <- qt(1 - alpha, df)

Tval <- .6 * (xbar - h0) / s * sqrt(n)

ifelse(Tval > crit, "Reject the null", "Cannot reject null")
```

b.) $\bar{X}_t = 43, s_w = 9$

```{r, echo = T}
xbar <- 43; s <- 9;

Tval <- .6 * (xbar - h0) / s * sqrt(n)

ifelse(Tval > crit, "Reject the null", "Cannot reject null")
```

c.) $\bar{X}_t = 43, s_w = 3$

```{r, echo = T}
xbar <- 43; s <- 3;

Tval <- .6 * (xbar - h0) / s * sqrt(n)

ifelse(Tval > crit, "Reject the null", "Cannot reject null")
```

### 7.32

For the data in Exercise 24, the 20% trimmed mean is $\bar{X}_t = 42.17$ with a Winsorized standard deviation of $S_w = 1.73$

Test the hypothesis that the population trimmed mean is 45 with $\alpha = 0.05$

```{r, echo = T}
x <- c(38, 44, 62, 72, 43, 40, 43, 42, 39, 41)

trim <- .2; alpha <- 0.05; h0 <- 45; n <- length(x)
xbar <- mean(x, tr = trim)
sw <- 1.73

g <- floor( trim * n )
df <- n - 2*g - 1

crit <- qt(1 - alpha/2, df)

score <- ( 1 - 2*trim ) * (xbar - h0) / sw * sqrt(n)

ifelse(abs(score) > crit, "Reject", "Fail to reject")
```

### 7.33

A standard measure of aggression in 7-year-old children has been found to have a 20% trimmed mean of 4.8 based on years of experience. A psychologiest wants to know whether the trimmed mean for children with divorced parents is greater than or less than 4.8.

Suppose $\bar{X}_t = 5.1, s_w = 7$ based on $n = 25$

Test $H_0 : \mu_t = 4.8, \alpha = 0.01$

```{r, echo = T}
xbar <- 5.1; sw <- 7; n <- 25
alpha <- 0.01; h0 <- 4.8; trim <- .2

g <- floor(n*trim)

df <- n - 2*g - 1

crit <- qt(1 - alpha/2, df)

score <- (1 - 2*trim) * (xbar - h0) / sw * sqrt(n)

ifelse(abs(score) > crit, "Reject", "Fail to reject")
```

### 7.34

Summarize the relative merits of using a percentile bootstrap method.


### 7.35

For the data in R variable _x_, imagine that you want to compute Z with the goal of testing the hypothesis that $\mu = 6$. Assuming that the R variable _null.value_ contains the hypothesized value and that _sigma_ contains the standard deviation, indicate the R command for computing Z.

test <- (mean(x) - null.value) / sigma * length(x)

### 7.36

R has a built-in data set called _ToothGrowth_. Information about the data can be obtained with the R command ?ToothGrowth. The first column contains measures of tooth growth in guinea pigs and the third column indicates the dose levels of vitaime C that were used in the experiment.

Consider the claim that the typical growth is 8 when the vitamine C level is 0.5 mg. Using R, verify that with Student's T and $\alpha = 0.05$, it would be decided that the population mean is larger than 8.

```{r, echo = T}
flag=which(ToothGrowth[,3]==0.5)
trimci(ToothGrowth[flag,1],null.value=8,tr=0)
```

Verify that no decision would be made based on the Tukey-McLaughlin method with a 20% trimmed mean.

```{r, echo = T}
trimci(ToothGrowth[flag,1],tr=0.2,null.value=8)
```

Plot the data and comment why the two methods give different results.

```{r, echo = T}
akerd(ToothGrowth[flag,1])
```

### 7.37

Based on the results for the previous exercise, speculate about whether you would reject using a median or MOM.

Use R to check your speculation.

```{r, echo = T}
id=which(ToothGrowth[,3]==0.5)
momci(ToothGrowth[id,1],null.value=8)
```
